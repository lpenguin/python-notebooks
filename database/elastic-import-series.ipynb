{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all samples into elastic search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import IndicesClient\n",
    "from elasticsearch_dsl import Mapping, String, Integer, Nested, Date, Object\n",
    "from elasticsearch.helpers import bulk\n",
    "import pymongo\n",
    "from time import sleep\n",
    "from lib.utils import iter_bucket\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "ies = IndicesClient(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_name = 'series_dev'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping and creating index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if ies.exists(index_name):\n",
    "    ies.delete(index_name)\n",
    "ies.create(index_name)\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mapping and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ies.close(index_name)\n",
    "m = Mapping(index_name)\n",
    "\n",
    "m.field('accession', String(index='not_analyzed'))\n",
    "m.field('contact', Object(enabled=False))\n",
    "m.field('contributor', String(index='no'))\n",
    "m.field('data_source', String(index='not_analyzed'))\n",
    "m.field('email', String(index='no'))\n",
    "\n",
    "meta = Object()\n",
    "meta.field('geo_id', Integer(index='not_analyzed'))\n",
    "\n",
    "m.field('meta', meta)\n",
    "m.field('organism', String(index='not_analyzed'))\n",
    "m.field('overall_design', String())\n",
    "m.field('platforms', String(index='not_analyzed', multi=True))\n",
    "m.field('pubmed_id', String(index='no'))\n",
    "m.field('relations', Object(enabled=False))\n",
    "m.field('samples', String(index='not_analyzed', multi=True))\n",
    "m.field('scrap_date', String(index='no'))\n",
    "m.field('status', String(index='not_analyzed'))\n",
    "m.field('submission_date', String(index='no'))\n",
    "m.field('summary', String())\n",
    "supplementary_files = Nested()\n",
    "supplementary_files.field(\"type\", String(index='not_analyzed'))\n",
    "supplementary_files.field(\"name\", String(index='not_analyzed'))\n",
    "\n",
    "m.field('supplementary_files', supplementary_files)\n",
    "\n",
    "m.field('title', String())\n",
    "m.field('type', String(index='not_analyzed', multi=True))\n",
    "m.field('web_link', String(index='not_analyzed'))\n",
    "\n",
    "m.save(index_name, using=es)\n",
    "\n",
    "# ies.put_settings(index=index_name, body={\n",
    "#     \"analysis\":{\n",
    "#       \"analyzer\":{\n",
    "#         \"default\":{\n",
    "#           \"type\":\"custom\",\n",
    "#           \"tokenizer\":\"standard\",\n",
    "#           \"filter\":[ \"standard\", \"lowercase\", \"stop\", \"kstem\" ]\n",
    "#         }\n",
    "#       }\n",
    "#     }\n",
    "# })\n",
    "sleep(1)\n",
    "ies.open(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fields(fields_list):\n",
    "    return dict((f, 1) for f in fields_list)\n",
    "\n",
    "def del_id(item):\n",
    "    if '_id' in item:\n",
    "        del item['_id']\n",
    "    return item\n",
    "    \n",
    "\n",
    "def make_raw_chars(item):\n",
    "    if 'characteristics_raw' in item:\n",
    "        return item\n",
    "    if not item.get('characteristics'):\n",
    "        return item\n",
    "\n",
    "    ch_raw = []\n",
    "    for k, v in item['characteristics'].items():\n",
    "        if isinstance(v, list):\n",
    "            v = ','.join(v)\n",
    "        v = v.strip(\" \")\n",
    "        if not v:\n",
    "            continue\n",
    "            \n",
    "        ch_raw.append('{}: {}'.format(k, v))\n",
    "                      \n",
    "    item['characteristics_raw'] = ch_raw\n",
    "    \n",
    "    del item['characteristics']\n",
    "    return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only fields in mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dump(dump_file):\n",
    "    with open(dump_file) as f:\n",
    "        for l in f:\n",
    "            l = l.rstrip('\\n')\n",
    "            yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "fields_list = list(m.to_dict()[index_name]['properties'].keys())\n",
    "fs = fields(fields_list)\n",
    "fs['_id'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-10-29T16:52:48.084+0000\tconnected to: localhost\n",
      "2015-10-29T16:52:59.081+0000\texported 66380 records\n"
     ]
    }
   ],
   "source": [
    "!mongoexport -d  scraper_test_dev -c series \\\n",
    "--out /data/rawdata/snapshots/mongo/scraper_test_dev.series.$(date +%Y%m%d.%H%M%S).json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing from dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_date(item):\n",
    "    def convert(field):\n",
    "        if field in item:\n",
    "            if item.get(field) and '$date' in item[field]:\n",
    "                d = item[field]['$date']\n",
    "                item[field] = d\n",
    "    \"\"\"\n",
    "    \"submission_date\": {\n",
    "    \"$date\": \"2000-09-28T00:00:00.000Z\"\n",
    "  },\n",
    "  \"scrap_date\": {\n",
    "    \"$date\": \"2015-09-22T12:03:46.782Z\"\n",
    "  }\n",
    "  \"last_update_date\": {\n",
    "    \"$date\": \"2008-11-19T00:00:00.000Z\"\n",
    "  },\n",
    "    \"\"\"\n",
    "    convert('submission_date')\n",
    "    convert('scrap_date')\n",
    "    convert('last_update_date')\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "samples_iter = read_dump('/data/rawdata/snapshots/mongo/scraper_test_dev.series.20151029.165247.json')\n",
    "for bucket in iter_bucket(map(convert_date, samples_iter)):\n",
    "    actions = [dict(\n",
    "                _index=index_name,\n",
    "                _type=index_name,\n",
    "                _source=s\n",
    "                ) for s in bucket]\n",
    "    \n",
    "    b += len(actions)\n",
    "    bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66380"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing from array-express data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695951\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "fs['characteristics'] = 1\n",
    "for bucket in iter_bucket(db.samples.find({'data_source': 'array-express'}, fs)):\n",
    "    actions = [dict(\n",
    "                _index=index_name,\n",
    "                _type=index_name,\n",
    "                _source=make_raw_chars(s)\n",
    "                ) for s in bucket]\n",
    "#     print(actions)\n",
    "    b += len(actions)\n",
    "    bulk(es, actions)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695951"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
